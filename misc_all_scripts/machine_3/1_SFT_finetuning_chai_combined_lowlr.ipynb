{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93be5e80-9035-4367-a268-c64650d42a90",
   "metadata": {},
   "source": [
    "# Import/install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb5a369-e6b1-4760-bc09-a47d6b47674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from vllm) (2025.7.34)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (6.1.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (2.1.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
      "Requirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.0.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.53.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.54.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.33.0->vllm) (0.34.3)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (6.31.1)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.116.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.12.15)\n",
      "Requirement already satisfied: openai<=1.90.0,>=1.87.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.90.0)\n",
      "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.7)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.0.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (7.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.11)\n",
      "Requirement already satisfied: llguidance<0.8.0,>=0.7.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.7.30)\n",
      "Requirement already satisfied: outlines_core==0.2.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.10)\n",
      "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.11/dist-packages (from vllm) (5.6.3)\n",
      "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.2.2)\n",
      "Requirement already satisfied: xgrammar==0.1.21 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.21)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.12.2)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.16.1)\n",
      "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.1.1.post6)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (26.3.0)\n",
      "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n",
      "Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.17.1)\n",
      "Requirement already satisfied: mistral_common>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from mistral_common[audio,image]>=1.8.2->vllm) (1.8.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.12.0.88)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.10.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.2)\n",
      "Requirement already satisfied: depyf==0.19.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
      "Requirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from vllm) (1.1.0)\n",
      "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.16.1)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm) (1.11.1.4)\n",
      "Requirement already satisfied: pybase64 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.4.2)\n",
      "Requirement already satisfied: cbor2 in /usr/local/lib/python3.11/dist-packages (from vllm) (5.6.5)\n",
      "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.61.2)\n",
      "Requirement already satisfied: ray!=2.44.*,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.48.0)\n",
      "Requirement already satisfied: torch==2.7.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.7.1)\n",
      "Requirement already satisfied: torchaudio==2.7.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.7.1)\n",
      "Requirement already satisfied: torchvision==0.22.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.22.1)\n",
      "Requirement already satisfied: xformers==0.0.31 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.0.31)\n",
      "Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.8.1)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.61.2->vllm) (0.44.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->vllm) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch==2.7.1->vllm) (77.0.1)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.47.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.8 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.8)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.35.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (24.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm) (1.1.5)\n",
      "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer<0.11,>=0.10.11->vllm) (0.3.3)\n",
      "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.23.0)\n",
      "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.10.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<=1.90.0,>=1.87.0->vllm) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->vllm) (0.4.1)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.2.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.1)\n",
      "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.1.31)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->vllm) (0.5.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\n",
      "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
      "Requirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.14.9)\n",
      "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.1->vllm) (2.1.5)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.23.1)\n",
      "Requirement already satisfied: pycountry>=23 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (24.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.1->vllm) (1.3.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.13.1)\n",
      "Requirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.5.0.post1)\n",
      "Requirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.34.1)\n",
      "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.17.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting flash-attn\n",
      "  Downloading flash_attn-2.8.2.tar.gz (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.7.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch->flash-attn) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.8.2-cp311-cp311-linux_x86_64.whl size=255941375 sha256=bf8e2091a699751a2311586c0a26f49e6ee6ed305ab85d0d50873f747e27cbab\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/67/59/31ba3e82c0d8ff661e94711512b3e41e07ac561aed265acb72\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: flash-attn\n",
      "Successfully installed flash-attn-2.8.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.7.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.54.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.9.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.34.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2024.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch>=1.13.0->peft) (77.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.20.0)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.9.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.0.0)\n",
      "Requirement already satisfied: transformers>=4.53.2 in /usr/local/lib/python3.11/dist-packages (from trl) (4.54.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.34.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2024.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->trl) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.53.2->trl) (0.21.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.1.31)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch>=2.0.0->accelerate>=1.4.0->trl) (77.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch<3,>=2.2->bitsandbytes) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (2.1.5)\n",
      "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.46.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.34.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch>=2.0.0->accelerate) (77.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.1.31)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install vllm\n",
    "!pip install datasets\n",
    "!pip install flash-attn --no-build-isolation\n",
    "!pip install peft\n",
    "!pip install trl\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd9c170-87ab-462c-b34c-40eed514dd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug  3 05:45:30 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  |   00000000:01:00.0 Off |                    0 |\n",
      "| N/A   51C    P0             52W /  300W |       1MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe04381-35c4-4836-9419-f83c6548c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ed71e-f1d7-4a71-a427-8b630b196ef0",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b06c25cb-b9fb-4e6b-a3a3-4d08b26019cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full script for fine-tuning Mistral-Nemo-Instruct-2407 for Role-Playing\n",
    "# using the official Mistral-Instruct chat template.\n",
    "\n",
    "# =====================================================================================\n",
    "# Step 0: Install Dependencies\n",
    "# =====================================================================================\n",
    "# !pip install -qU \"transformers==4.43.3\" \"datasets==2.20.0\" \"accelerate==0.32.0\" \"bitsandbytes==0.43.1\" \"peft==0.11.1\" \"trl==0.9.4\"\n",
    "# !pip install -qU \"flash-attn==2.6.2\" --no-build-isolation\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =====================================================================================\n",
    "# 1. Configuration\n",
    "# =====================================================================================\n",
    "# Model and tokenizer names\n",
    "base_model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
    "# Name for the LoRA adapter directory\n",
    "new_model_name = \"Mistral-Nemo-2407-LORA-combineddata-8ac-lr2e6\"\n",
    "# Name for the final merged model directory\n",
    "final_model_name = \"Mistral-Nemo-2407-LORA-combineddata-8ac-lr2e6\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e4a5d6-b4ea-416c-8d4b-bb49e5736e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Total combined and processed examples: 44139\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"combined_data_old_format.jsonl\", \"r\") as f:\n",
    "    all_examples = [json.loads(line) for line in f]\n",
    "\n",
    "unified_dataset = Dataset.from_list(all_examples).shuffle(seed=42)\n",
    "print(f\"\\n✅ Total combined and processed examples: {len(unified_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbebe3f-a650-43bd-89b2-17013df6aa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Hello there, how can I help \\n\\n Hi, I just wanted to talk with someone',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Of course, what about?', 'role': 'assistant'},\n",
       "  {'content': 'I just wanted to talk in general', 'role': 'user'},\n",
       "  {'content': 'That sounds great, I love talking about anything and everything',\n",
       "   'role': 'assistant'},\n",
       "  {'content': \"That's good\", 'role': 'user'},\n",
       "  {'content': 'So tell me about yourself', 'role': 'assistant'},\n",
       "  {'content': \"Well, my name is Seán. I'm 19 and I'm bisexual\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'Oh really? What kind of things do you enjoy doing?',\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'I like to read and play video games', 'role': 'user'},\n",
       "  {'content': 'video games!', 'role': 'assistant'},\n",
       "  {'content': 'Yeah', 'role': 'user'},\n",
       "  {'content': 'Do you have any favorite ones?', 'role': 'assistant'},\n",
       "  {'content': 'Not really', 'role': 'user'},\n",
       "  {'content': 'Hmm, well what kind of things do you like to read?',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4911c96d-2227-415a-b915-51f4b2c5a1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded Mistral-Nemo-Instruct-2407 tokenizer\n",
      "\n",
      "--- Test Case 1 ---\n",
      "Input messages:\n",
      "  user: 'Hello there, how can I help \\n\\n Hi, I just wanted to talk with someone'\n",
      "  assistant: 'Of course, what about?'\n",
      "  user: 'I just wanted to talk in general'\n",
      "  assistant: 'That sounds great, I love talking about anything and everything'\n",
      "  user: \"That's good\"\n",
      "  assistant: 'So tell me about yourself'\n",
      "  user: \"Well, my name is Seán. I'm 19 and I'm bisexual\"\n",
      "  assistant: 'Oh really? What kind of things do you enjoy doing?'\n",
      "  user: 'I like to read and play video games'\n",
      "  assistant: 'video games!'\n",
      "  user: 'Yeah'\n",
      "  assistant: 'Do you have any favorite ones?'\n",
      "  user: 'Not really'\n",
      "  assistant: 'Hmm, well what kind of things do you like to read?'\n",
      "\n",
      "Formatted output:\n",
      "\"<s>[INST]Hello there, how can I help \\n\\n Hi, I just wanted to talk with someone[/INST]Of course, what about?</s>[INST]I just wanted to talk in general[/INST]That sounds great, I love talking about anything and everything</s>[INST]That's good[/INST]So tell me about yourself</s>[INST]Well, my name is Seán. I'm 19 and I'm bisexual[/INST]Oh really? What kind of things do you enjoy doing?</s>[INST]I like to read and play video games[/INST]video games!</s>[INST]Yeah[/INST]Do you have any favorite ones?</s>[INST]Not really[/INST]Hmm, well what kind of things do you like to read?</s>\"\n",
      "\n",
      "Token count: 136\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "\n",
    "def check_mistral_chat_template():\n",
    "    \"\"\"\n",
    "    Check and test the chat template for Mistral-Nemo-Instruct-2407\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the tokenizer which contains the chat template\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-Nemo-Instruct-2407\")\n",
    "        print(\"✅ Successfully loaded Mistral-Nemo-Instruct-2407 tokenizer\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading tokenizer: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Test cases including edge cases with brackets\n",
    "    \n",
    "    test_cases = [\n",
    "        unified_dataset[0]['messages']\n",
    "    ]\n",
    "    \n",
    "    for i, messages in enumerate(test_cases, 1):\n",
    "        print(f\"\\n--- Test Case {i} ---\")\n",
    "        print(\"Input messages:\")\n",
    "        for msg in messages:\n",
    "            print(f\"  {msg['role']}: {repr(msg['content'])}\")\n",
    "        \n",
    "        try:\n",
    "            # Apply chat template\n",
    "            formatted = tokenizer.apply_chat_template(\n",
    "                messages, \n",
    "                tokenize=False, \n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            print(\"\\nFormatted output:\")\n",
    "            print(repr(formatted))\n",
    "            # print(\"\\nRendered output:\")\n",
    "            # print(formatted)\n",
    "            \n",
    "            # Also test tokenization\n",
    "            tokens = tokenizer.apply_chat_template(\n",
    "                messages, \n",
    "                tokenize=True, \n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            print(f\"\\nToken count: {len(tokens)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing: {e}\")\n",
    "        \n",
    "        print(\"-\" * 30)\n",
    "check_mistral_chat_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06376574-1741-4362-bb22-eb26123d5a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca66c7ee-7968-4ff8-a375-7c8f6e54b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Setting up model, tokenizer, and configurations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62dea1d8e8df42e8a11fd6b9ca817215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =====================================================================================\n",
    "# 4. Model and Tokenizer Setup\n",
    "# =====================================================================================\n",
    "from transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "print(\"\\n🔧 Setting up model, tokenizer, and configurations...\")\n",
    "\n",
    "# Load the base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    # quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3aca38-cda1-43af-bd05-553c03fd4b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mistral Instruct chat template configured.\n"
     ]
    }
   ],
   "source": [
    "# --- THIS IS THE KEY CHANGE ---\n",
    "# Define the official Mistral Instruct template, modified to handle a system prompt\n",
    "MISTRAL_INSTRUCT_TEMPLATE = (\n",
    "    \"{{ bos_token }}\"\n",
    "    \"{% set system_message_found = false %}\"\n",
    "    \"{% for message in messages %}\"\n",
    "        \"{% if message['role'] == 'system' %}\"\n",
    "            \"{% set system_message = message['content'] %}\"\n",
    "            \"{% set system_message_found = true %}\"\n",
    "        \"{% elif message['role'] == 'user' %}\"\n",
    "            \"{% if loop.first and system_message_found %}\"\n",
    "                \"{{ '[INST] ' + system_message + '\\\\n' + message['content'] + ' [/INST]' }}\"\n",
    "            \"{% else %}\"\n",
    "                \"{{ '[INST] ' + message['content'] + ' [/INST]' }}\"\n",
    "            \"{% endif %}\"\n",
    "        \"{% elif message['role'] == 'assistant' %}\"\n",
    "            \"{{ ' ' + message['content'] + eos_token }}\"\n",
    "        \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    ")\n",
    "tokenizer.chat_template = MISTRAL_INSTRUCT_TEMPLATE\n",
    "print(\"✅ Mistral Instruct chat template configured.\")\n",
    "\n",
    "# PEFT/LoRA Configuration\n",
    "lora_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=32,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e2a64a0-a8ed-47c7-9f26-65695a5ff9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages'],\n",
       "    num_rows: 44139\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d52c16a-8c2f-466b-8cb2-a10a8f560f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9172336aa4f4cce96662d91e63f6654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template:   0%|          | 0/44139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'formatted_text'],\n",
       "    num_rows: 44139\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def apply_chat_template(dataset, tokenizer, text_column=\"messages\"):\n",
    "    \"\"\"\n",
    "    Apply chat template to a dataset with messages field.\n",
    "    \n",
    "    Args:\n",
    "        dataset: HuggingFace Dataset with messages field\n",
    "        tokenizer: HuggingFace tokenizer with chat template\n",
    "        text_column: Name of the column containing messages (default: \"messages\")\n",
    "    \n",
    "    Returns:\n",
    "        Dataset with templated and tokenized text\n",
    "    \"\"\"\n",
    "    \n",
    "    def format_example(example):\n",
    "        # Apply the chat template to the messages\n",
    "        # Assumes messages is a list of dicts with 'role' and 'content' keys\n",
    "        formatted_text = tokenizer.apply_chat_template(\n",
    "            example[text_column], \n",
    "            tokenize=False,  # Get string first, then tokenize separately\n",
    "            add_generation_prompt=False  # Set to True if you want to add generation prompt\n",
    "        )\n",
    "        \n",
    "        # Tokenize the formatted text\n",
    "        tokenized = tokenizer(\n",
    "            formatted_text,\n",
    "            truncation=True,\n",
    "            padding=False,  # Usually done in batches later\n",
    "            return_tensors=None  # Return lists, not tensors\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "            \"formatted_text\": formatted_text  # Keep for debugging\n",
    "        }\n",
    "    \n",
    "    # Apply the formatting function to the dataset\n",
    "    formatted_dataset = dataset.map(\n",
    "        format_example,\n",
    "        remove_columns=[text_column],  # Remove original messages column\n",
    "        desc=\"Applying chat template\"\n",
    "    )\n",
    "    \n",
    "    return formatted_dataset\n",
    "\n",
    "# Apply chat template\n",
    "formatted_dataset = apply_chat_template(unified_dataset, tokenizer)\n",
    "formatted_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222008e8-8753-437e-abff-779ad149185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_dataset['formatted_text'][10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "901218e6-d273-46dd-9e7d-1aff8b04aeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f5c11bfce94654b6a41c2dae7c7aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/44139 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚂 Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5254' max='5518' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5254/5518 4:07:53 < 12:27, 0.35 it/s, Epoch 1.90/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.153500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.783600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.254700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.874900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.715200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.700800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.482500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.371700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.376500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.321100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.213100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.235800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.065100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.188900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.988400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.126900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.878400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.799300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.747100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.085200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.038600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.667300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>2.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.638500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>2.067100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>2.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.607600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>2.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>2.623300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>1.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>2.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>2.600400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>1.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.600300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>1.967500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>2.600900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>1.966600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.583200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>2.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>2.541500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>1.992400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.570200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>1.943400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>2.545100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>1.942700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.568700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>1.965500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.573400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>1.990300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.548600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>1.962800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>1.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.541000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>1.957500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>2.525400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1775</td>\n",
       "      <td>1.933800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.556700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1825</td>\n",
       "      <td>1.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>2.517600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>2.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.565800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1925</td>\n",
       "      <td>1.900300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>2.553500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1975</td>\n",
       "      <td>1.951800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.517400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2025</td>\n",
       "      <td>1.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>2.541400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2075</td>\n",
       "      <td>1.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.604400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2125</td>\n",
       "      <td>1.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>2.517200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2175</td>\n",
       "      <td>1.948300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2225</td>\n",
       "      <td>1.919300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>2.553800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2275</td>\n",
       "      <td>1.924600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.507200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2325</td>\n",
       "      <td>1.924500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>2.557700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2375</td>\n",
       "      <td>1.925200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.535700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2425</td>\n",
       "      <td>1.959700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>2.503000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2475</td>\n",
       "      <td>1.934500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.512300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2525</td>\n",
       "      <td>1.971200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>2.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2575</td>\n",
       "      <td>1.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2625</td>\n",
       "      <td>1.928700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>2.558900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2675</td>\n",
       "      <td>1.923400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.517800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2725</td>\n",
       "      <td>1.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>2.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2775</td>\n",
       "      <td>1.978100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2825</td>\n",
       "      <td>2.130600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>2.303300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2875</td>\n",
       "      <td>2.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.289900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2925</td>\n",
       "      <td>2.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>2.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2975</td>\n",
       "      <td>2.151900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.270900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3025</td>\n",
       "      <td>2.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>2.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3075</td>\n",
       "      <td>2.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.288900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3125</td>\n",
       "      <td>2.136300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>2.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3175</td>\n",
       "      <td>2.160900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.268500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3225</td>\n",
       "      <td>2.111700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>2.308900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>2.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>2.301100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3325</td>\n",
       "      <td>2.131400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>2.327500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3375</td>\n",
       "      <td>2.165900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.338900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3425</td>\n",
       "      <td>2.108000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>2.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3475</td>\n",
       "      <td>2.083700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3525</td>\n",
       "      <td>2.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>2.290800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3575</td>\n",
       "      <td>2.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3625</td>\n",
       "      <td>2.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>2.300600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3675</td>\n",
       "      <td>2.129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.255600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>2.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>2.275800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3775</td>\n",
       "      <td>2.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.273300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3825</td>\n",
       "      <td>2.087700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>2.318300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3875</td>\n",
       "      <td>2.151800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3925</td>\n",
       "      <td>2.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>2.317900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3975</td>\n",
       "      <td>2.087700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.278300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4025</td>\n",
       "      <td>2.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>2.293800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4075</td>\n",
       "      <td>2.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>2.301500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4125</td>\n",
       "      <td>2.119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>2.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4175</td>\n",
       "      <td>2.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.263800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4225</td>\n",
       "      <td>2.158600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>2.306400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4275</td>\n",
       "      <td>2.142200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>2.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4325</td>\n",
       "      <td>2.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>2.303900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4375</td>\n",
       "      <td>2.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.262700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4425</td>\n",
       "      <td>2.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>2.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4475</td>\n",
       "      <td>2.150300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4525</td>\n",
       "      <td>2.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>2.283800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4575</td>\n",
       "      <td>2.141200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>2.259100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4625</td>\n",
       "      <td>2.145200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>2.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4675</td>\n",
       "      <td>2.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>2.266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4725</td>\n",
       "      <td>2.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>2.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4775</td>\n",
       "      <td>2.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>2.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4825</td>\n",
       "      <td>2.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>2.297200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4875</td>\n",
       "      <td>2.119800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>2.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4925</td>\n",
       "      <td>2.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>2.310100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4975</td>\n",
       "      <td>2.185700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.273500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5025</td>\n",
       "      <td>2.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>2.303700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5075</td>\n",
       "      <td>2.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>2.279200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5125</td>\n",
       "      <td>2.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>2.234800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5175</td>\n",
       "      <td>2.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>2.261600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5225</td>\n",
       "      <td>2.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>2.261100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:    25 | Loss: 2.904100 | LR: 0.00000029\n",
      "Step:    50 | Loss: 4.153500 | LR: 0.00000059\n",
      "Step:    75 | Loss: 2.783600 | LR: 0.00000089\n",
      "Step:   100 | Loss: 4.254700 | LR: 0.00000119\n",
      "Step:   125 | Loss: 2.874900 | LR: 0.00000149\n",
      "Step:   150 | Loss: 4.043200 | LR: 0.00000180\n",
      "Step:   175 | Loss: 2.715200 | LR: 0.00000200\n",
      "Step:   200 | Loss: 3.700800 | LR: 0.00000200\n",
      "Step:   225 | Loss: 2.482500 | LR: 0.00000200\n",
      "Step:   250 | Loss: 3.539700 | LR: 0.00000200\n",
      "Step:   275 | Loss: 2.371700 | LR: 0.00000200\n",
      "Step:   300 | Loss: 3.376500 | LR: 0.00000200\n",
      "Step:   325 | Loss: 2.321100 | LR: 0.00000200\n",
      "Step:   350 | Loss: 3.314100 | LR: 0.00000199\n",
      "Step:   375 | Loss: 2.213100 | LR: 0.00000199\n",
      "Step:   400 | Loss: 3.147500 | LR: 0.00000199\n",
      "Step:   425 | Loss: 2.235800 | LR: 0.00000199\n",
      "Step:   450 | Loss: 3.065100 | LR: 0.00000199\n",
      "Step:   475 | Loss: 2.188900 | LR: 0.00000198\n",
      "Step:   500 | Loss: 2.988400 | LR: 0.00000198\n",
      "Step:   525 | Loss: 2.126900 | LR: 0.00000198\n",
      "Step:   550 | Loss: 2.878400 | LR: 0.00000197\n",
      "Step:   575 | Loss: 2.121600 | LR: 0.00000197\n",
      "Step:   600 | Loss: 2.799300 | LR: 0.00000197\n",
      "Step:   625 | Loss: 2.125500 | LR: 0.00000196\n",
      "Step:   650 | Loss: 2.747100 | LR: 0.00000196\n",
      "Step:   675 | Loss: 2.101600 | LR: 0.00000196\n",
      "Step:   700 | Loss: 2.800400 | LR: 0.00000195\n",
      "Step:   725 | Loss: 2.085200 | LR: 0.00000195\n",
      "Step:   750 | Loss: 2.687500 | LR: 0.00000194\n",
      "Step:   775 | Loss: 2.038600 | LR: 0.00000194\n",
      "Step:   800 | Loss: 2.707200 | LR: 0.00000193\n",
      "Step:   825 | Loss: 2.001700 | LR: 0.00000193\n",
      "Step:   850 | Loss: 2.667300 | LR: 0.00000192\n",
      "Step:   875 | Loss: 2.018200 | LR: 0.00000191\n",
      "Step:   900 | Loss: 2.638500 | LR: 0.00000191\n",
      "Step:   925 | Loss: 2.067100 | LR: 0.00000190\n",
      "Step:   950 | Loss: 2.595500 | LR: 0.00000190\n",
      "Step:   975 | Loss: 2.006200 | LR: 0.00000189\n",
      "Step:  1000 | Loss: 2.607600 | LR: 0.00000188\n",
      "Step:  1050 | Loss: 2.623300 | LR: 0.00000187\n",
      "Step:  1075 | Loss: 1.990000 | LR: 0.00000186\n",
      "Step:  1100 | Loss: 2.564700 | LR: 0.00000185\n",
      "Step:  1125 | Loss: 2.015600 | LR: 0.00000185\n",
      "Step:  1150 | Loss: 2.600400 | LR: 0.00000184\n",
      "Step:  1175 | Loss: 1.954900 | LR: 0.00000183\n",
      "Step:  1200 | Loss: 2.600300 | LR: 0.00000182\n",
      "Step:  1275 | Loss: 1.966600 | LR: 0.00000180\n",
      "Step:  1300 | Loss: 2.583200 | LR: 0.00000179\n",
      "Step:  1325 | Loss: 2.018700 | LR: 0.00000178\n",
      "Step:  1350 | Loss: 2.541500 | LR: 0.00000177\n",
      "Step:  1375 | Loss: 1.992400 | LR: 0.00000176\n",
      "Step:  1400 | Loss: 2.570200 | LR: 0.00000175\n",
      "Step:  1450 | Loss: 2.545100 | LR: 0.00000173\n",
      "Step:  1475 | Loss: 1.942700 | LR: 0.00000172\n",
      "Step:  1500 | Loss: 2.568700 | LR: 0.00000171\n",
      "Step:  1525 | Loss: 1.965500 | LR: 0.00000170\n",
      "Step:  1550 | Loss: 2.573400 | LR: 0.00000169\n",
      "Step:  1575 | Loss: 1.990300 | LR: 0.00000168\n",
      "Step:  1600 | Loss: 2.548600 | LR: 0.00000167\n",
      "Step:  1625 | Loss: 1.962800 | LR: 0.00000166\n",
      "Step:  1650 | Loss: 2.533000 | LR: 0.00000164\n",
      "Step:  1675 | Loss: 1.975800 | LR: 0.00000163\n",
      "Step:  1700 | Loss: 2.541000 | LR: 0.00000162\n",
      "Step:  1725 | Loss: 1.957500 | LR: 0.00000161\n",
      "Step:  1750 | Loss: 2.525400 | LR: 0.00000160\n",
      "Step:  1775 | Loss: 1.933800 | LR: 0.00000159\n",
      "Step:  1800 | Loss: 2.556700 | LR: 0.00000157\n",
      "Step:  1825 | Loss: 1.957600 | LR: 0.00000156\n",
      "Step:  1850 | Loss: 2.517600 | LR: 0.00000155\n",
      "Step:  1875 | Loss: 2.021500 | LR: 0.00000154\n",
      "Step:  1900 | Loss: 2.565800 | LR: 0.00000153\n",
      "Step:  1925 | Loss: 1.900300 | LR: 0.00000151\n",
      "Step:  1950 | Loss: 2.553500 | LR: 0.00000150\n",
      "Step:  1975 | Loss: 1.951800 | LR: 0.00000149\n",
      "Step:  2000 | Loss: 2.517400 | LR: 0.00000147\n",
      "Step:  2025 | Loss: 1.971000 | LR: 0.00000146\n",
      "Step:  2050 | Loss: 2.541400 | LR: 0.00000145\n",
      "Step:  2075 | Loss: 1.958600 | LR: 0.00000144\n",
      "Step:  2100 | Loss: 2.604400 | LR: 0.00000142\n",
      "Step:  2125 | Loss: 1.975800 | LR: 0.00000141\n",
      "Step:  2150 | Loss: 2.517200 | LR: 0.00000140\n",
      "Step:  2175 | Loss: 1.948300 | LR: 0.00000138\n",
      "Step:  2200 | Loss: 2.558000 | LR: 0.00000137\n",
      "Step:  2225 | Loss: 1.919300 | LR: 0.00000135\n",
      "Step:  2250 | Loss: 2.553800 | LR: 0.00000134\n",
      "Step:  2275 | Loss: 1.924600 | LR: 0.00000133\n",
      "Step:  2300 | Loss: 2.507200 | LR: 0.00000131\n",
      "Step:  2325 | Loss: 1.924500 | LR: 0.00000130\n",
      "Step:  2375 | Loss: 1.925200 | LR: 0.00000127\n",
      "Step:  2400 | Loss: 2.535700 | LR: 0.00000126\n",
      "Step:  2425 | Loss: 1.959700 | LR: 0.00000124\n",
      "Step:  2450 | Loss: 2.503000 | LR: 0.00000123\n",
      "Step:  2475 | Loss: 1.934500 | LR: 0.00000121\n",
      "Step:  2500 | Loss: 2.512300 | LR: 0.00000120\n",
      "Step:  2525 | Loss: 1.971200 | LR: 0.00000119\n",
      "Step:  2550 | Loss: 2.486000 | LR: 0.00000117\n",
      "Step:  2575 | Loss: 1.975000 | LR: 0.00000116\n",
      "Step:  2600 | Loss: 2.546100 | LR: 0.00000114\n",
      "Step:  2625 | Loss: 1.928700 | LR: 0.00000113\n",
      "Step:  2650 | Loss: 2.558900 | LR: 0.00000111\n",
      "Step:  2675 | Loss: 1.923400 | LR: 0.00000110\n",
      "Step:  2700 | Loss: 2.517800 | LR: 0.00000108\n",
      "Step:  2725 | Loss: 1.954600 | LR: 0.00000107\n",
      "Step:  2750 | Loss: 2.521700 | LR: 0.00000105\n",
      "Step:  2775 | Loss: 1.978100 | LR: 0.00000104\n",
      "Step:  2800 | Loss: 2.299300 | LR: 0.00000103\n",
      "Step:  2825 | Loss: 2.130600 | LR: 0.00000101\n",
      "Step:  2850 | Loss: 2.303300 | LR: 0.00000100\n",
      "Step:  2875 | Loss: 2.176000 | LR: 0.00000098\n",
      "Step:  2900 | Loss: 2.289900 | LR: 0.00000097\n",
      "Step:  2925 | Loss: 2.156900 | LR: 0.00000095\n",
      "Step:  2950 | Loss: 2.312800 | LR: 0.00000094\n",
      "Step:  2975 | Loss: 2.151900 | LR: 0.00000092\n",
      "Step:  3000 | Loss: 2.270900 | LR: 0.00000091\n",
      "Step:  3025 | Loss: 2.136700 | LR: 0.00000089\n",
      "Step:  3050 | Loss: 2.209800 | LR: 0.00000088\n",
      "Step:  3075 | Loss: 2.140000 | LR: 0.00000086\n",
      "Step:  3100 | Loss: 2.288900 | LR: 0.00000085\n",
      "Step:  3125 | Loss: 2.136300 | LR: 0.00000084\n",
      "Step:  3150 | Loss: 2.339200 | LR: 0.00000082\n",
      "Step:  3175 | Loss: 2.160900 | LR: 0.00000081\n",
      "Step:  3200 | Loss: 2.268500 | LR: 0.00000079\n",
      "Step:  3225 | Loss: 2.111700 | LR: 0.00000078\n",
      "Step:  3250 | Loss: 2.308900 | LR: 0.00000076\n",
      "Step:  3275 | Loss: 2.102400 | LR: 0.00000075\n",
      "Step:  3300 | Loss: 2.301100 | LR: 0.00000073\n",
      "Step:  3325 | Loss: 2.131400 | LR: 0.00000072\n",
      "Step:  3350 | Loss: 2.327500 | LR: 0.00000071\n",
      "Step:  3375 | Loss: 2.165900 | LR: 0.00000069\n",
      "Step:  3400 | Loss: 2.338900 | LR: 0.00000068\n",
      "Step:  3425 | Loss: 2.108000 | LR: 0.00000066\n",
      "Step:  3450 | Loss: 2.295700 | LR: 0.00000065\n",
      "Step:  3475 | Loss: 2.083700 | LR: 0.00000064\n",
      "Step:  3500 | Loss: 2.317800 | LR: 0.00000062\n",
      "Step:  3525 | Loss: 2.126500 | LR: 0.00000061\n",
      "Step:  3550 | Loss: 2.290800 | LR: 0.00000060\n",
      "Step:  3575 | Loss: 2.122300 | LR: 0.00000058\n",
      "Step:  3600 | Loss: 2.282000 | LR: 0.00000057\n",
      "Step:  3625 | Loss: 2.174100 | LR: 0.00000056\n",
      "Step:  3650 | Loss: 2.300600 | LR: 0.00000054\n",
      "Step:  3675 | Loss: 2.129900 | LR: 0.00000053\n",
      "Step:  3700 | Loss: 2.255600 | LR: 0.00000052\n",
      "Step:  3725 | Loss: 2.153200 | LR: 0.00000051\n",
      "Step:  3750 | Loss: 2.275800 | LR: 0.00000049\n",
      "Step:  3775 | Loss: 2.103900 | LR: 0.00000048\n",
      "Step:  3800 | Loss: 2.273300 | LR: 0.00000047\n",
      "Step:  3825 | Loss: 2.087700 | LR: 0.00000045\n",
      "Step:  3850 | Loss: 2.318300 | LR: 0.00000044\n",
      "Step:  3875 | Loss: 2.151800 | LR: 0.00000043\n",
      "Step:  3900 | Loss: 2.304800 | LR: 0.00000042\n",
      "Step:  3925 | Loss: 2.145700 | LR: 0.00000041\n",
      "Step:  3950 | Loss: 2.317900 | LR: 0.00000039\n",
      "Step:  3975 | Loss: 2.087700 | LR: 0.00000038\n",
      "Step:  4000 | Loss: 2.278300 | LR: 0.00000037\n",
      "Step:  4025 | Loss: 2.117600 | LR: 0.00000036\n",
      "Step:  4050 | Loss: 2.293800 | LR: 0.00000035\n",
      "Step:  4075 | Loss: 2.137500 | LR: 0.00000034\n",
      "Step:  4100 | Loss: 2.301500 | LR: 0.00000033\n",
      "Step:  4125 | Loss: 2.119200 | LR: 0.00000032\n",
      "Step:  4150 | Loss: 2.262000 | LR: 0.00000031\n",
      "Step:  4175 | Loss: 2.123100 | LR: 0.00000030\n",
      "Step:  4200 | Loss: 2.263800 | LR: 0.00000029\n",
      "Step:  4225 | Loss: 2.158600 | LR: 0.00000027\n",
      "Step:  4250 | Loss: 2.306400 | LR: 0.00000026\n",
      "Step:  4275 | Loss: 2.142200 | LR: 0.00000025\n",
      "Step:  4300 | Loss: 2.266000 | LR: 0.00000025\n",
      "Step:  4325 | Loss: 2.110500 | LR: 0.00000024\n",
      "Step:  4350 | Loss: 2.303900 | LR: 0.00000023\n",
      "Step:  4375 | Loss: 2.137600 | LR: 0.00000022\n",
      "Step:  4400 | Loss: 2.262700 | LR: 0.00000021\n",
      "Step:  4425 | Loss: 2.102000 | LR: 0.00000020\n",
      "Step:  4450 | Loss: 2.339200 | LR: 0.00000019\n",
      "Step:  4475 | Loss: 2.150300 | LR: 0.00000018\n",
      "Step:  4500 | Loss: 2.285600 | LR: 0.00000017\n",
      "Step:  4525 | Loss: 2.122200 | LR: 0.00000017\n",
      "Step:  4550 | Loss: 2.283800 | LR: 0.00000016\n",
      "Step:  4575 | Loss: 2.141200 | LR: 0.00000015\n",
      "Step:  4600 | Loss: 2.259100 | LR: 0.00000014\n",
      "Step:  4625 | Loss: 2.145200 | LR: 0.00000013\n",
      "Step:  4650 | Loss: 2.291800 | LR: 0.00000013\n",
      "Step:  4675 | Loss: 2.086100 | LR: 0.00000012\n",
      "Step:  4700 | Loss: 2.266500 | LR: 0.00000011\n",
      "Step:  4725 | Loss: 2.141500 | LR: 0.00000011\n",
      "Step:  4750 | Loss: 2.278600 | LR: 0.00000010\n",
      "Step:  4775 | Loss: 2.104900 | LR: 0.00000009\n",
      "Step:  4800 | Loss: 2.217100 | LR: 0.00000009\n",
      "Step:  4825 | Loss: 2.097600 | LR: 0.00000008\n",
      "Step:  4850 | Loss: 2.297200 | LR: 0.00000008\n",
      "Step:  4875 | Loss: 2.119800 | LR: 0.00000007\n",
      "Step:  4900 | Loss: 2.287500 | LR: 0.00000007\n",
      "Step:  4925 | Loss: 2.182700 | LR: 0.00000006\n",
      "Step:  4950 | Loss: 2.310100 | LR: 0.00000006\n",
      "Step:  4975 | Loss: 2.185700 | LR: 0.00000005\n",
      "Step:  5000 | Loss: 2.273500 | LR: 0.00000005\n",
      "Step:  5025 | Loss: 2.118400 | LR: 0.00000004\n",
      "Step:  5050 | Loss: 2.303700 | LR: 0.00000004\n",
      "Step:  5075 | Loss: 2.173300 | LR: 0.00000003\n",
      "Step:  5100 | Loss: 2.279200 | LR: 0.00000003\n",
      "Step:  5125 | Loss: 2.132800 | LR: 0.00000003\n",
      "Step:  5150 | Loss: 2.234800 | LR: 0.00000002\n",
      "Step:  5175 | Loss: 2.088900 | LR: 0.00000002\n",
      "Step:  5200 | Loss: 2.261600 | LR: 0.00000002\n",
      "Step:  5225 | Loss: 2.176600 | LR: 0.00000001\n",
      "Step:  5250 | Loss: 2.261100 | LR: 0.00000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================================\n",
    "# 5. Training\n",
    "# =====================================================================================\n",
    "# =====================================================================================\n",
    "from transformers import TrainerCallback, TrainerControl, TrainerState, Trainer\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "class LrLoggerCallback(TrainerCallback):\n",
    "    def on_log(self, args, state: TrainerState, control: TrainerControl, logs=None, **kwargs):\n",
    "        if logs is not None and \"loss\" in logs:\n",
    "            lr = logs.get(\"learning_rate\", \"N/A\")\n",
    "            step = state.global_step\n",
    "            loss = logs[\"loss\"]\n",
    "            print(f\"Step: {step:>5} | Loss: {loss:.6f} | LR: {lr:.8f}\")\n",
    "\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=new_model_name,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=500,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-6,\n",
    "    weight_decay=0.001,\n",
    "    bf16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",  # or \"cosine_with_restarts\"\n",
    "    # report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# def tokenize(example):\n",
    "#     return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=2048)\n",
    "\n",
    "# tokenized_dataset = unified_dataset[0].map(tokenize)\n",
    "\n",
    "# SFT Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=formatted_dataset,\n",
    "    peft_config=lora_config,\n",
    "    # max_seq_length=2048,\n",
    "    # tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    # packing=True, # Improves efficiency by packing short sequences together\n",
    "    callbacks=[LrLoggerCallback()],\n",
    ")\n",
    "\n",
    "print(\"\\n🚂 Starting training...\")\n",
    "trainer.train()\n",
    "print(\"✅ Training complete.\")\n",
    "\n",
    "# Save the LoRA adapter\n",
    "trainer.save_model(new_model_name)\n",
    "print(f\"✅ LoRA adapter saved to {new_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78aab094-6271-424a-a6d7-b36ba7a9808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧬 Merging model and preparing for upload...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7f6e6735b34c24ab7bf93e6de613b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model merged.\n",
      "✅ Final merged model saved to Mistral-Nemo-2407-LORA-combineddata-8ac-lr2e6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================================================\n",
    "# 6. Merge Model and Save Final Version\n",
    "# =====================================================================================\n",
    "print(\"\\n🧬 Merging model and preparing for upload...\")\n",
    "\n",
    "# Reload the base model in FP16 for merging\n",
    "base_model_for_merge = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Load the PEFT model with the saved adapter\n",
    "merged_model = PeftModel.from_pretrained(base_model_for_merge, new_model_name)\n",
    "# Merge the adapter into the base model\n",
    "merged_model = merged_model.merge_and_unload()\n",
    "print(\"✅ Model merged.\")\n",
    "\n",
    "# Save the final, merged model and its tokenizer\n",
    "merged_model.save_pretrained(final_model_name)\n",
    "tokenizer.save_pretrained(final_model_name)\n",
    "print(f\"✅ Final merged model saved to {final_model_name}\")\n",
    "\n",
    "# To push to hub, run this after logging in via `huggingface-cli login`:\n",
    "# merged_model.push_to_hub(final_model_name)\n",
    "# tokenizer.push_to_hub(final_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3726a987-494f-464b-afb5-a87ed9f8177d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e657d82932d144998c7ca799e7c82579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc452925cc74e889794e75d375e72dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535e672a90ce49ff8c27c3546a415a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16f7a94733544808c93208db1fe8d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f88856a3164ea28308219a2d98dcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c5fb5d457d487ca28dd19b57f9c375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/4.91G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_model.push_to_hub(final_model_name)\n",
    "tokenizer.push_to_hub(final_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e69d34f-733c-4a19-aef8-d2fadd599ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Running inference test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffe56b43bdf462281b7f4d01d1b435b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INFERENCE RESULT ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m full_output = outputs[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mgenerated_text\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Extract just the assistant's latest response for cleaner display\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m assistant_response = \u001b[43mfull_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m[/INST]\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m].strip()\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(assistant_response)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- END OF SCRIPT ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================================================\n",
    "# 7. Inference Test\n",
    "# =====================================================================================\n",
    "print(\"\\n🧪 Running inference test...\")\n",
    "\n",
    "# Define a persona and a starting message\n",
    "test_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a weary, old wizard named Elara. You are suspicious of strangers but possess deep knowledge of ancient magic. You speak in a cryptic and slightly paranoid manner.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Greetings, old one. I seek knowledge of the Sunken City.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Use the Hugging Face pipeline for easy inference\n",
    "# This will automatically use the chat template we configured!\n",
    "pipe = pipeline(\"text-generation\", model=final_model_name, tokenizer=tokenizer, torch_dtype=torch.bfloat16)\n",
    "outputs = pipe(test_messages, max_new_tokens=150, do_sample=True, temperature=0.7, top_p=0.9, top_k=50)\n",
    "\n",
    "print(\"\\n--- INFERENCE RESULT ---\")\n",
    "# The pipeline output includes the full conversation string\n",
    "full_output = outputs[0]['generated_text']\n",
    "\n",
    "# Extract just the assistant's latest response for cleaner display\n",
    "assistant_response = full_output.split('[/INST]')[-1].strip()\n",
    "print(assistant_response)\n",
    "print(\"--- END OF SCRIPT ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391d7cd-ad27-4e9c-b170-cd4595884fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
